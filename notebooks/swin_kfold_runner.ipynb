{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0e41ab-4a25-4ec9-8e6b-db4182795787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../lib/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba1285b-13b5-459b-8904-c4bc95a8b7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn import model_selection\n",
    "from uuid import uuid4\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import tez\n",
    "\n",
    "from configuration import load_configuration\n",
    "from constants import ColumnNames\n",
    "from image_transforms import (\n",
    "    cnn_training_transform,\n",
    "    cnn_inferencing_transform\n",
    ")\n",
    "\n",
    "from datasets import PetfinderImageSet\n",
    "from models.swin import PawpularSwinModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9087d67-d731-4aac-a127-54182fc23068",
   "metadata": {},
   "source": [
    "# set up and configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9f35b7-2b44-4875-bca9-cebef3ccc04f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Settings not currently in the configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a1bdc-6724-4766-a532-327499a211f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_KAGLE = False # flag to not if we're in KAGLE and should set paths etc accordingly\n",
    "TRAIN = True # if False will just load and make submission \n",
    "TRAIN &= IS_KAGLE # TRAIN should always be False when running in kaggle\n",
    "\n",
    "LOAD_MODEL = \"\" # only needed when TRAIN is False\n",
    "\n",
    "EARLY_STOPPING_PATIENCE = 11 # how many epocs with no improvment before we stop training. This has reached a point where it should be added to the config soon\n",
    "N_FOLDS = 10 # should probably be added to configuration.yaml at some point\n",
    "USE_HOLDOUT = True # for testing internally we should use a hold out dataset to better measure improvments. but if we are training for submission we should use all the data \n",
    "FEATURE_RESCALLING = False # this is only needed if we add new features, eventually might make it into our config file but for now set here\n",
    "LOW_PRECISION_TRAINING = True # reduces 32 bit to 16 bit for faster training\n",
    "\n",
    "# the scheduler and optimizer are hard one to get into the configuration\n",
    "# these might be things that are specfific to and individual notebook / experiment \n",
    "# so these settings will only exist within notebooks using cosine annealing\n",
    "COSINE_ANNEALING_T0 =5\n",
    "COSINE_ANNEALING_Tmulit =1\n",
    "COSINE_ANNEALING_eta_min = 1e-7\n",
    "\n",
    "configuration_file = \"configuration_exp_20.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0302f539-be92-4424-b187-db993c318ea1",
   "metadata": {},
   "source": [
    "## Setting the save folder and paths (shouldn't need to change anything here most of the time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45f5158-da19-4b85-8d0c-7bdf296bbcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_date = datetime.now().strftime(\"%Y_%m_%d_%H\")\n",
    "save_folder = Path('../') / \"experiments\" / f'conf_{configuration_file[:-5]}_{save_date}'\n",
    "save_folder.mkdir(exist_ok=True)\n",
    "print(f\"saving in {save_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc09cda-bb79-4d7c-a871-481dc8f36c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_KAGLE:\n",
    "    base_dir = Path('/kaggle')\n",
    "    test_img_dir = base_dir / 'input/petfinder-pawpularity-score/test'\n",
    "    test_data_csv = base_dir / 'input/petfinder-pawpularity-score/test.csv'\n",
    "    train_img_dir = base_dir / 'input/petfinder-pawpularity-score/train'\n",
    "    train_data_csv = base_dir / 'input/petfinder-pawpularity-score/train.csv'\n",
    "    sumbission_csv = base_dir / 'input/petfinder-pawpularity-score/sample_submission.csv'\n",
    "    temp_dir = base_dir / 'temp'\n",
    "    store_dir = base_dir / 'working'\n",
    "    test_submission_path = base_dir/ 'input/pawpularity-submission/submission.csv'\n",
    "    load_dir =  base_dir/ f'pawpular_model_{LOAD_MODEL}'\n",
    "    config = load_configuration(configuration_path = base_dir / f'input/../input/d/kruskal/kapet-lib/{configuration_file}')\n",
    "else:\n",
    "    base_dir = Path('../')\n",
    "    test_img_dir = base_dir / 'input/test'\n",
    "    test_data_csv = base_dir / 'input/test.csv'\n",
    "    train_img_dir = base_dir / 'input/train'\n",
    "    train_data_csv = base_dir / 'input/train.csv'\n",
    "    sumbission_csv = base_dir / 'input/sample_submission.csv'\n",
    "    store_dir = base_dir / 'experiments'\n",
    "    test_submission_path = base_dir/ 'input/pawpularity-submission/submission.csv'\n",
    "    load_dir = save_folder\n",
    "    config = load_configuration(configuration_path = base_dir / f'lib/{configuration_file}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27e257e-a90c-403b-8223-16465e994317",
   "metadata": {},
   "source": [
    "# prepping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5205a2e7-6a71-498c-9d88-533d830a286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_image_path(data,img_dir):\n",
    "    data[ColumnNames.image_path.value] = data[ColumnNames.image_name.value].map(lambda x : img_dir / (x + \".jpg\"))\n",
    "    return data\n",
    "\n",
    "def load_csv_to_dataset(csv_path,image_dir,config,inference = True):\n",
    "    data = pd.read_csv(csv_path)\n",
    "    data = add_image_path(data, image_dir)\n",
    "    if ColumnNames.label.value not in data.columns:\n",
    "        data[ColumnNames.label.value] = 0\n",
    "        \n",
    "    if inference:\n",
    "        transform = cnn_inferencing_transform(config)\n",
    "    else:\n",
    "        transform = cnn_training_transform(config)\n",
    "\n",
    "    dataset = PetfinderImageSet(\n",
    "        config, image_dir, images_df=data, transform=transform\n",
    "    )\n",
    "    \n",
    "    return data, dataset\n",
    "\n",
    "train_data = pd.read_csv(train_data_csv)\n",
    "test_data = pd.read_csv(test_data_csv)\n",
    "\n",
    "train_data = add_image_path(train_data,train_img_dir)\n",
    "test_data = add_image_path(test_data,test_img_dir)\n",
    "\n",
    "train_data.head()\n",
    "print(f\"total files in image train dir {len(list(train_img_dir.glob('*.*')))}\")\n",
    "print(f\"total jpgs in image test dir {len(list(test_img_dir.glob('*.jpg')))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f57014-427d-4cc8-bc85-edf15f844752",
   "metadata": {},
   "source": [
    "## Generate data splits\n",
    "Going to make a hold out data set if specified\n",
    "Ideally if we want to train a final model for submission and we think it has a good set of hyper paramaters we would skip this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebed60b4-c98a-474c-94fa-a5d2eaf9b3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data[ColumnNames.label.value]\n",
    "\n",
    "if USE_HOLDOUT:\n",
    "    # x_hold_out and y_hold_out are to be used in as a secondary assecment of fold performance\n",
    "    # different then the validation sets in a fold which are used for early stopping criteria\n",
    "    X, X_hold_out, y, y_hold_out = model_selection.train_test_split(\n",
    "        train_data, y, train_size=0.9, random_state=2019, shuffle=True, stratify=y)\n",
    "else:\n",
    "    X = train_data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecd6e29-e741-43cb-b13f-08015bd3ea91",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842fc1d8-0a2a-4ba7-927e-75eade5d1e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    holdout_losses = []\n",
    "    validation_losses = []\n",
    "    training_losses = []\n",
    "    timing_list = []\n",
    "    k_folds = model_selection.KFold(n_splits=N_FOLDS, random_state=2019, shuffle=True)\n",
    "    for i_fold, (train_index, test_index) in enumerate(k_folds.split(X)):\n",
    "        tic = time.time()\n",
    "        X_train = X.iloc[train_index]\n",
    "        X_validation = X.iloc[test_index]\n",
    "        y_train = y.iloc[train_index]\n",
    "        y_validation = y.iloc[test_index]\n",
    "\n",
    "        # rescale features specific to this fold\n",
    "        if FEATURE_RESCALLING\n",
    "            scaler = StandardScaler()\n",
    "            scaler = scaler.fit(X_train[config.regression_config.features_to_use])\n",
    "            X_train[config.regression_config.features_to_use] = scaler.transform(\n",
    "                X_train[config.regression_config.features_to_use]\n",
    "            )\n",
    "            X_validation[config.regression_config.features_to_use] = scaler.transform(\n",
    "                X_validation[config.regression_config.features_to_use]\n",
    "            )\n",
    "            if USE_HOLDOUT:\n",
    "                X_hold_out[config.regression_config.features_to_use] = scaler.transform(\n",
    "                    X_hold_out[config.regression_config.features_to_use]\n",
    "                )= torch.optim.Adam(model.parameters(), lr=model.learning_rate)\n",
    "\n",
    "        # build data sets\n",
    "        dataset_train = PetfinderImageSet(\n",
    "            config, train_img_dir, images_df=X_train, transform=cnn_training_transform(config)\n",
    "        )\n",
    "        dataset_validation = PetfinderImageSet(\n",
    "            config, train_img_dir, images_df=X_validation, transform=cnn_inferencing_transform(config)\n",
    "        )\n",
    "        \n",
    "        print(f'train size {len(dataset_train)} batches {len(dataset_train) / config.cnn_config.batch_size}')\n",
    "        print(f'validation size {len(dataset_validation)} batches {len(dataset_validation) / config.cnn_config.batch_size}')\n",
    "        if USE_HOLDOUT:\n",
    "            print(f'internal testing size {len(dataset_hold_out)} batches {len(dataset_hold_out) / config.cnn_config.batch_size}')\n",
    "\n",
    "        model = PawpularSwinModel(\n",
    "            config.cnn_config.model_configuration,\n",
    "            learning_rate=config.cnn_config.learning_rate,\n",
    "            number_of_latent_image_features=128,\n",
    "            number_of_additional_features=len(config.regression_config.features_to_use),\n",
    "            number_of_intermediate_regression_variables=64,\n",
    "            regression_dropout=0.2,\n",
    "            model_drop_rate=0.1\n",
    "        )\n",
    "\n",
    "        model.optimizer = torch.optim.Adam(model.parameters(), lr=config.cnn_config.learning_rate)\n",
    "        model.scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "                model.optimizer, T_0=COSINE_ANNEALING_T0, T_mult=COSINE_ANNEALING_Tmulit, eta_min=COSINE_ANNEALING_eta_min, last_epoch=-1\n",
    "            ) \n",
    "        \n",
    "\n",
    "        model.step_scheduler_after = \"epoch\"\n",
    "\n",
    "        # early stopping callback, you can also write your own callback\n",
    "        early_stopping = tez.callbacks.EarlyStopping(\n",
    "            monitor=\"valid_loss\",\n",
    "            model_path=save_folder / f\"best_model_fold_{i_fold}.bin\",\n",
    "            patience=EARLY_STOPPING_PATIENCE\n",
    "        )\n",
    "\n",
    "        # train model using the tez framework\n",
    "        model.fit(\n",
    "            train_dataset=dataset_train,\n",
    "            valid_dataset = dataset_validation,\n",
    "            train_bs=config.cnn_config.batch_size,\n",
    "            valid_bs=config.cnn_config.batch_size,\n",
    "            device=config.device,\n",
    "            fp16=LOW_PRECISION_TRAINING,\n",
    "            epochs=config.cnn_config.epochs,\n",
    "            callbacks=[early_stopping],\n",
    "            accumulation_steps=config.cnn_config.accumulation_steps  # needed for memory constraints\n",
    "        )\n",
    "\n",
    "        # save model (with optimizer and scheduler for future!)\n",
    "        model.save(save_folder / f\"final_model_{i_fold}.bin\")\n",
    "        \n",
    "        # reload the best model version\n",
    "        model.load(save_folder / f\"best_model_fold_{i_fold}.bin\")\n",
    "        \n",
    "        # get the best predictions for both validation and train datasets\n",
    "        validation_loss = model.validate_one_epoch(\n",
    "            data_loader=model.valid_loader\n",
    "        )\n",
    "        training_loss = model.validate_one_epoch(\n",
    "            data_loader=model.train_loader\n",
    "        )\n",
    "\n",
    "        # store\n",
    "        validation_losses.append(validation_loss)\n",
    "        training_losses.append(training_loss)\n",
    "        \n",
    "        # run time store\n",
    "        timing = time.time()-tic\n",
    "        timing_list.append(timing)\n",
    "\n",
    "\n",
    "        # some clean up\n",
    "        del dataset_validation\n",
    "        del dataset_train\n",
    "        gc.collect()\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # test the holdout scores\n",
    "        if USE_HOLDOUT:\n",
    "            dataset_hold_out = PetfinderImageSet(\n",
    "                config, train_img_dir, images_df=X_hold_out, transform=cnn_inferencing_transform(config)\n",
    "            )\n",
    "            hold_out_loader = torch.utils.data.DataLoader(\n",
    "                dataset_hold_out,\n",
    "                batch_size=8\n",
    "            )\n",
    "            holdout_loss = model.validate_one_epoch(\n",
    "                data_loader=hold_out_loader\n",
    "            )\n",
    "            holdout_losses.append(holdout_loss)\n",
    "            print(f\"Finished fold {i_fold} in {timing} with holdout loss {holdout_loss}\")\n",
    "\n",
    "            del hold_out_loader\n",
    "            del dataset_hold_out\n",
    "        \n",
    "        # even more clean up\n",
    "        del model\n",
    "        gc.collect()\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7798614f-c060-432c-8512-3028ca86cfce",
   "metadata": {},
   "source": [
    "# Report on Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350891b1-b362-4fa6-971c-032302b8d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    if USE_HOLDOUT:\n",
    "        #create 95% confidence interval for population mean weight\n",
    "        holdout_loss_confidence = stats.t.interval(\n",
    "            alpha=0.95,\n",
    "            df=len(holdout_losses)-1,\n",
    "            loc=np.mean(holdout_losses),\n",
    "            scale=stats.sem(holdout_losses)\n",
    "        )\n",
    "    validation_loss_confidence = stats.t.interval(\n",
    "        alpha=0.95,\n",
    "        df=len(validation_losses)-1,\n",
    "        loc=np.mean(validation_losses),\n",
    "        scale=stats.sem(validation_losses)\n",
    "    )\n",
    "    training_loss_confidence = stats.t.interval(\n",
    "        alpha=0.95,\n",
    "        df=len(training_losses)-1,\n",
    "        loc=np.mean(training_losses),\n",
    "        scale=stats.sem(training_losses)\n",
    "    )\n",
    "\n",
    "\n",
    "    print(\"-.-\")\n",
    "    print(\"________________________\")\n",
    "    print(\"\\_ o _/\")\n",
    "    print(f\"folds ran in {np.sum(timing_list)} with and average of {np.mean(timing_list)}  per fold\")\n",
    "    \n",
    "    \n",
    "    if USE_HOLDOUT:\n",
    "        print(\"holdout_losses\")\n",
    "        print(holdout_losses)\n",
    "        print(f\"mean holdout loss {np.mean(holdout_losses)}\")\n",
    "        print(f\"hold out loss 95% bounds {holdout_loss_confidence}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51649f6c-5cc0-40ea-a0d7-3e534f1ebbfa",
   "metadata": {},
   "source": [
    "# Run on test data\n",
    "only really needed for final submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371c3be7-7c3a-41e1-bcac-7538c0e4a528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only makes sense to do any of this if we are making a submission on kaggle unsless we are testing the workbook functionality\n",
    "if IS_KAGGLE:\n",
    "    test_dataframe, dataset_test = load_csv_to_dataset(test_data_csv, test_img_dir, config, inference=True)\n",
    "\n",
    "    model = PawpularSwinModel(\n",
    "            config.cnn_config.model_configuration,\n",
    "            learning_rate=config.cnn_config.learning_rate,\n",
    "            number_of_latent_image_features=128,\n",
    "            number_of_additional_features=len(config.regression_config.features_to_use),\n",
    "            number_of_intermediate_regression_variables=64,\n",
    "            regression_dropout=0.2,\n",
    "            model_drop_rate=0.1\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582ad759-0af4-49a1-bd66-e0b10225738d",
   "metadata": {},
   "source": [
    "## run the fold loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cb43c6-2348-4815-bc91-1d590567fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_KAGGLE:\n",
    "    train_predictions = []\n",
    "    timing_list = []\n",
    "    for i_fold in range(number_of_folds):\n",
    "        model.load(load_folder / f\"best_model_fold_{i_fold}.bin\", device=\"cuda\")\n",
    "\n",
    "        predictions = model.predict(\n",
    "            dataset_test,\n",
    "            batch_size=config.cnn_config.batch_size\n",
    "        )\n",
    "        these_test_predictions = []\n",
    "        for preds in predictions:  # tqdm\n",
    "            these_test_predictions.extend(preds[:, :1].ravel().tolist())\n",
    "        test_predictions.append(these_test_predictions)\n",
    "\n",
    "        # some clean up\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7325012e-3017-4090-898e-e2e71fb1e208",
   "metadata": {},
   "source": [
    "## get averaged results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357d4b59-f15e-4dd3-9127-a3da6b24c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_KAGGLE:\n",
    "    mean_predictions = np.mean(np.column_stack(test_predictions), axis=1)\n",
    "    submission = test_dataframe[[\"Id\", \"Pawpularity\"]]\n",
    "    submission[\"Pawpularity\"] = mean_predictions\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "    submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
